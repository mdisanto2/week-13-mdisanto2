{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![DSB logo](img/Dolan.jpg)\n",
    "# Groupby and Pivoting\n",
    "\n",
    "## PD4E Chapter 10: Groupby Operations: Split-Apply-Combine\n",
    "### How do you read/manipulate/store data in Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What You Learned in Python/Pandas that could Apply Here\n",
    "\n",
    "You will need following knowledge from the first half of this course:\n",
    "1. functions\n",
    "2. subsetting/slicing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What You will Learn in this Chapter\n",
    "\n",
    "You will learn following techniques in this chapter:\n",
    "1. Groupby operations to aggregate, transform, and filter data\n",
    "2. Built-in and custom user function to perform groupby functions\n",
    "3. creating _pivot tables_ from DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What do we mean by Groupby operations?\n",
    "\n",
    "- Groupby operations is how we aggregate, transform and filter data\n",
    "    - you will learn the `SQL GROUPBY` in BA 510\n",
    "- We follow the mantra below:\n",
    "    - data is separated into different parts based on their feature(s);\n",
    "    - we apply applicable function(s) to different parts of the data;\n",
    "    - then we combine different parts of processed data back as the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why do we need to do this?\n",
    "\n",
    "- we may need to select subsets of a DataFrame using certain conditions\n",
    "    - like how we calculate the `final_pay` based on `work_load` last week\n",
    "- or in data analytics\n",
    "    - we have different standardized processing pipelines for _categorical_ and _continuous_ features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Aggregation\n",
    "\n",
    "- Aggregation is a term we use in databases, or particularly data warehouses\n",
    "    - aggregation also known as summarization, it means data reduction\n",
    "    - most of descriptive stats, such as count, mean, standard deviation, are summarization methods\n",
    "    - the data size is essentially smaller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Aggregation Examples\n",
    "\n",
    "- it refers to moving from a more specific data to a more abstract level\n",
    "    - e.g., if the actual data is daily-based, and we want to get the monthly sum/average of the data\n",
    "    - or if the observation are scattered in different years, and we want to look at the annual averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'./data/gapminder.tsv' does not exist: b'./data/gapminder.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2f3c7179189a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# please change your PATH to `'/srv/data/my_shared_data_folder/ba505-data/gapminder.tsv'`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/gapminder.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'./data/gapminder.tsv' does not exist: b'./data/gapminder.tsv'"
     ]
    }
   ],
   "source": [
    "# an example of aggregation\n",
    "# load the gapminder data\n",
    "# please change your PATH to `'/srv/data/my_shared_data_folder/ba505-data/gapminder.tsv'`\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./data/gapminder.tsv', sep='\\t')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# calculate the annual average life expectancy for each year\n",
    "df.groupby('year')['lifeExp'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# this is the longer alternative\n",
    "df['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df1952 = df[df['year'] == 1952]\n",
    "df1952mean = df1952['lifeExp'].mean()\n",
    "df1952mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Built-in Aggregation Methods\n",
    "\n",
    "- In above example, you noticed that we calculate the average life expactacies for each individual year\n",
    "    - average is one of the __aggregation method__\n",
    "    - there are other aggregation methods available\n",
    "    - refer to PD4E pp. 192 for all applicable aggregation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# note that ball  columns in the \n",
    "# results below can be aggregation methods\n",
    "df.groupby('continent')['lifeExp'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Aggregation Methods\n",
    "\n",
    "- So far we have been using aggregation methods directly\n",
    "- but in general we can use the `.agg()` method for any aggregation function\n",
    "    - you should consider `.agg()` as a special case of `.apply()`\n",
    "- there are two use cases for using `.agg()`\n",
    "    - we can only use `pandas` built-in aggregation methods (column 1 in Table 10.1) directly, but sometimes we prefer using the `numpy` alternatives (column 2 in Table 10.1) - since they are much faster\n",
    "    - we can even use custom aggregation functions/methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# numpy method - numpy is always faster than pandas\n",
    "%time\n",
    "import numpy as np\n",
    "df.groupby('continent')['lifeExp'].agg(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# custom aggregation function\n",
    "def my_mean(values): # our own version of mean calculation\n",
    "    # get total number of values\n",
    "    return sum(values)/len(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('continent')['lifeExp'].agg(my_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# multiple aggregation function siultaneously\n",
    "df.groupby('continent')['lifeExp'].agg([np.count_nonzero, \n",
    "                                        np.mean, np.std, np.min, np.max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('continent')['lifeExp'].agg([np.count_nonzero, \n",
    "                                        np.mean, np.std]).rename(columns={'count_nonzero': 'count',\n",
    "                                                                          'mean':'avg',\n",
    "                                                                          'std':'std_dev'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Preferred `.groupby()` syntax\n",
    "\n",
    "- You should use following syntax when you use `.groupby()`\n",
    "    - the preferred syntax can handle different aggregation functions on different columns\n",
    "    \n",
    "```python\n",
    "df.groupby('grouping column').agg({'aggregating column': 'aggregating function'})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('continent').agg({'lifeExp': ['min', 'max'],\n",
    "                              'pop': ['min', 'max']\n",
    "                              }).round(0).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Transform Your Data\n",
    "\n",
    "- Transform is different from aggregation\n",
    "    - aggregate takes multiple values, and output one value (values --> annual average)\n",
    "    - transform take mukltiple values, and do a one-to-one transform\n",
    "    - transform is similar to apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# z-score example\n",
    "def my_zscore(x):\n",
    "    return(x-x.mean()/x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "z_transform = df.groupby('continent')['lifeExp'].transform(my_zscore)\n",
    "z_transform.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# one-to-one match - same dimension with `df`\n",
    "z_transform.shape[0] == df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# same as transform\n",
    "z_transform1 = df.groupby('continent')['lifeExp'].apply(my_zscore)\n",
    "z_transform1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# missing value example\n",
    "- Read PD4E pp. 199 - 201 for the example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Grouped - one of the most common names in pandas**\n",
    "\n",
    "- You can always group your data based on one or more columns\n",
    "- grouped objects are essentially subsets of your data, based on certain conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "tips10 = sns.load_dataset('tips').sample(10, random_state=2019)\n",
    "tips10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# this will return the grouped objects\n",
    "grouped = tips10.groupby('sex')\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# to unpack the grouped objects, we need to use a loop\n",
    "for group in grouped:\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# we can do calculation to the grouped objects\n",
    "grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# selecting a group - a subset of your data\n",
    "grouped.get_group('Female')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# you can also group based on multiple columns\n",
    "tips10.groupby(['sex','time']).mean().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multi-index DataFrame\n",
    "\n",
    "- Above results, since it has two levels of indices, is called a _multi-index_ DataFrame\n",
    "- multi-index DataFrames are useful in the field of databases and data warehouses/BI\n",
    "- but strongly discouraged in machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# indexing can unpack the multi-index, by giving you a subset of the data\n",
    "tips10.groupby(['sex','time']).mean().loc['Male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# if you want to get all the data at the same level, you need `.reset_index()`\n",
    "# this operation is called __flattening__\n",
    "# almost a must do in machine learning\n",
    "tips10.groupby(['sex','time']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `pivot_table` in `pandas`\n",
    "\n",
    "- Like you used in Excel, `pandas` also support pivot tables\n",
    "- pivot tables are similar to `.groupby()`, but much cleaned\n",
    "    - `NaN` rows will be eliminated\n",
    "- Prefer `.pivot_table()` to `.groupby()` when you want to directly compare groups\n",
    "- Alternatively, use `.groupby()` when you want to iterate through groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "tips10.pivot_table(index=['sex', 'time'],\n",
    "                    values=['total_bill', 'tip', 'size'], aggfunc='mean').round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Crosstabs\n",
    "\n",
    "- pandas also provide a function `crosstab()`\n",
    "- only use that when you want to look at the relative frequency of a column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# following statement will give you the relative frequency of `day` over `sex`\n",
    "pd.crosstab(index=tips10['sex'], columns=tips10['day'], normalize='all').round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Your Turn Here\n",
    "Finish exercises below by following instructions of each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Q1. Coding Problem\n",
    "\n",
    "Complete excecises regarding data types of the given DataFrame (`itinery_df`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration_mins</th>\n",
       "      <th>work_types</th>\n",
       "      <th>locations</th>\n",
       "      <th>hour_rates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>593</td>\n",
       "      <td>lecture</td>\n",
       "      <td>Munich, Germany</td>\n",
       "      <td>18.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1288</td>\n",
       "      <td>research</td>\n",
       "      <td>Paris, France</td>\n",
       "      <td>17.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>833</td>\n",
       "      <td>consulting</td>\n",
       "      <td>Beijing, China</td>\n",
       "      <td>13.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1062</td>\n",
       "      <td>lecture</td>\n",
       "      <td>Beijing, China</td>\n",
       "      <td>16.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>345</td>\n",
       "      <td>lecture</td>\n",
       "      <td>Paris, France</td>\n",
       "      <td>17.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration_mins  work_types        locations  hour_rates\n",
       "0            593     lecture  Munich, Germany       18.56\n",
       "1           1288    research    Paris, France       17.16\n",
       "2            833  consulting   Beijing, China       13.72\n",
       "3           1062     lecture   Beijing, China       16.56\n",
       "4            345     lecture    Paris, France       17.43"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "# generating the DF\n",
    "duration_mins = pd.Series(random.sample(range(1, 1800), 50), name='duration_mins')\n",
    "work_types = ['lecture', 'consulting', 'research']\n",
    "work_type_series = pd.Series(random.choices(work_types, k=50), name='work_types')\n",
    "locations = ['Beijing, China', 'London, England', 'Paris, France', 'Munich, Germany', \n",
    "             'Sydney, Australia', 'Mumbai, India', 'Madrid, Spain']\n",
    "loc_series = pd.Series(random.choices(locations, k=50), name='locations')\n",
    "hour_rates = pd.Series([round(random.uniform(10.0, 20.0), 2) for i in range(50)], name='hour_rates')\n",
    "#hour_rates.loc[random.sample(range(1, 20), 5)] = 'missing'\n",
    "#duration_mins.loc[random.sample(range(1, 20), 5)] = 'missing'\n",
    "itinery_df = pd.concat([duration_mins, work_type_series, loc_series, hour_rates], axis=1)\n",
    "#itinery_df['duration_mins'] = itinery_df['duration_mins'].astype(str)\n",
    "itinery_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 1:\n",
    "\n",
    "Calculate the total working minutes (`durantion_mins`) by city, and answer which city has the highest total working minutes.\n",
    "\n",
    "__HINT__: use `.groupby()` with the aggregation function as `sum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 4 columns):\n",
      "duration_mins    50 non-null int64\n",
      "work_types       50 non-null object\n",
      "locations        50 non-null object\n",
      "hour_rates       50 non-null float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 1.7+ KB\n"
     ]
    }
   ],
   "source": [
    "itinery_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "locations\n",
       "Beijing, China        8459\n",
       "London, England       2870\n",
       "Madrid, Spain         4856\n",
       "Mumbai, India         1648\n",
       "Munich, Germany      10369\n",
       "Paris, France        14130\n",
       "Sydney, Australia     5268\n",
       "Name: duration_mins, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate working minutes by city\n",
    "itinery_df.groupby('locations')['duration_mins'].sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 2:\n",
    "\n",
    "Without using the `.describe()` method, calculate the `count`, `min`, `max`, `std`, `mean` of `hour_rates` grouped by `work_types`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_nonzero</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>amin</th>\n",
       "      <th>amax</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work_types</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>consulting</th>\n",
       "      <td>18.0</td>\n",
       "      <td>14.373889</td>\n",
       "      <td>2.660949</td>\n",
       "      <td>10.21</td>\n",
       "      <td>18.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lecture</th>\n",
       "      <td>16.0</td>\n",
       "      <td>14.481250</td>\n",
       "      <td>2.697673</td>\n",
       "      <td>11.19</td>\n",
       "      <td>18.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>research</th>\n",
       "      <td>16.0</td>\n",
       "      <td>14.805000</td>\n",
       "      <td>2.630904</td>\n",
       "      <td>11.17</td>\n",
       "      <td>19.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count_nonzero       mean       std   amin   amax\n",
       "work_types                                                  \n",
       "consulting           18.0  14.373889  2.660949  10.21  18.86\n",
       "lecture              16.0  14.481250  2.697673  11.19  18.62\n",
       "research             16.0  14.805000  2.630904  11.17  19.00"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate methods of hour_rates grouped by work_type\n",
    "import numpy as np\n",
    "itinery_df.groupby('work_types')['hour_rates'].agg([np.count_nonzero,\n",
    "                                                   np.mean, np.std, np.min, np.max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 3:\n",
    "\n",
    "Print out subset of `itinery_df` by different `locations`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Beijing, China',     duration_mins  work_types       locations  hour_rates\n",
      "2             833  consulting  Beijing, China       13.72\n",
      "3            1062     lecture  Beijing, China       16.56\n",
      "9             670    research  Beijing, China       13.95\n",
      "17           1203     lecture  Beijing, China       13.10\n",
      "19           1744     lecture  Beijing, China       12.14\n",
      "26           1109     lecture  Beijing, China       18.05\n",
      "28           1574    research  Beijing, China       16.35\n",
      "37            264    research  Beijing, China       15.98)\n",
      "('London, England',     duration_mins  work_types        locations  hour_rates\n",
      "14            367  consulting  London, England       16.68\n",
      "25            671     lecture  London, England       11.41\n",
      "29           1091  consulting  London, England       16.98\n",
      "41            741    research  London, England       16.37)\n",
      "('Madrid, Spain',     duration_mins  work_types      locations  hour_rates\n",
      "18           1271    research  Madrid, Spain       12.20\n",
      "31            461  consulting  Madrid, Spain       11.26\n",
      "32            323    research  Madrid, Spain       12.49\n",
      "36            791  consulting  Madrid, Spain       14.47\n",
      "39           1240    research  Madrid, Spain       12.36\n",
      "48            770     lecture  Madrid, Spain       13.97)\n",
      "('Mumbai, India',    duration_mins work_types      locations  hour_rates\n",
      "5           1648   research  Mumbai, India       13.44)\n",
      "('Munich, Germany',     duration_mins  work_types        locations  hour_rates\n",
      "0             593     lecture  Munich, Germany       18.56\n",
      "7             408  consulting  Munich, Germany       13.25\n",
      "8            1431     lecture  Munich, Germany       16.60\n",
      "10            514  consulting  Munich, Germany       13.61\n",
      "11           1360  consulting  Munich, Germany       17.75\n",
      "13           1348     lecture  Munich, Germany       11.77\n",
      "20            751    research  Munich, Germany       17.43\n",
      "30           1611  consulting  Munich, Germany       12.43\n",
      "33            968     lecture  Munich, Germany       14.24\n",
      "49           1385  consulting  Munich, Germany       13.65)\n",
      "('Paris, France',     duration_mins  work_types      locations  hour_rates\n",
      "1            1288    research  Paris, France       17.16\n",
      "4             345     lecture  Paris, France       17.43\n",
      "12           1351  consulting  Paris, France       16.76\n",
      "15           1250    research  Paris, France       18.75\n",
      "16           1605  consulting  Paris, France       11.80\n",
      "21           1585     lecture  Paris, France       12.49\n",
      "23            705  consulting  Paris, France       18.86\n",
      "27            436     lecture  Paris, France       11.19\n",
      "35             42    research  Paris, France       12.74\n",
      "38            594  consulting  Paris, France       12.78\n",
      "42           1164  consulting  Paris, France       16.97\n",
      "43            875    research  Paris, France       11.17\n",
      "44           1515     lecture  Paris, France       18.62\n",
      "45           1248     lecture  Paris, France       13.02\n",
      "47            127    research  Paris, France       19.00)\n",
      "('Sydney, Australia',     duration_mins  work_types          locations  hour_rates\n",
      "6            1663  consulting  Sydney, Australia       10.55\n",
      "22            159    research  Sydney, Australia       11.34\n",
      "24           1597  consulting  Sydney, Australia       10.21\n",
      "34           1247  consulting  Sydney, Australia       17.00\n",
      "40            551     lecture  Sydney, Australia       12.55\n",
      "46             51    research  Sydney, Australia       16.15)\n"
     ]
    }
   ],
   "source": [
    "#create a subset of itinery_df by locations\n",
    "grouped=itinery_df.groupby('locations')\n",
    "for group in grouped:\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4:\n",
    "\n",
    "Use `.pivot_table` to compare which `location` has the highest `hour_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour_rates</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>locations</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Beijing, China</th>\n",
       "      <td>14.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>London, England</th>\n",
       "      <td>15.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Madrid, Spain</th>\n",
       "      <td>12.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mumbai, India</th>\n",
       "      <td>13.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Munich, Germany</th>\n",
       "      <td>14.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paris, France</th>\n",
       "      <td>15.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sydney, Australia</th>\n",
       "      <td>12.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   hour_rates\n",
       "locations                    \n",
       "Beijing, China          14.98\n",
       "London, England         15.36\n",
       "Madrid, Spain           12.79\n",
       "Mumbai, India           13.44\n",
       "Munich, Germany         14.93\n",
       "Paris, France           15.25\n",
       "Sydney, Australia       12.97"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itinery_df.pivot_table(index=['locations'],\n",
    "                      values=['hour_rates'], aggfunc ='mean').round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5:\n",
    "\n",
    "Show the relative frequencies of `work_types` over different `locations`. (__HINT__: use `crosstab()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>locations</th>\n",
       "      <th>Beijing, China</th>\n",
       "      <th>London, England</th>\n",
       "      <th>Madrid, Spain</th>\n",
       "      <th>Mumbai, India</th>\n",
       "      <th>Munich, Germany</th>\n",
       "      <th>Paris, France</th>\n",
       "      <th>Sydney, Australia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work_types</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>consulting</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lecture</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>research</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "locations   Beijing, China  London, England  Madrid, Spain  Mumbai, India  \\\n",
       "work_types                                                                  \n",
       "consulting            0.02             0.04           0.04           0.00   \n",
       "lecture               0.08             0.02           0.02           0.00   \n",
       "research              0.06             0.02           0.06           0.02   \n",
       "\n",
       "locations   Munich, Germany  Paris, France  Sydney, Australia  \n",
       "work_types                                                     \n",
       "consulting             0.10            0.1               0.06  \n",
       "lecture                0.08            0.1               0.02  \n",
       "research               0.02            0.1               0.04  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index=itinery_df['work_types'], columns=itinery_df['locations'], normalize='all').round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Classwork (start here in class)\n",
    "You can start working on them right now:\n",
    "- Read Chapter 10 in PD4E \n",
    "- If time permits, start in on your homework. \n",
    "- Ask questions when you need help. Use this time to get help from the professor!\n",
    "\n",
    "# Homework (do at home)\n",
    "The following is due before class next week:\n",
    "  - Any remaining classwork from tonight\n",
    "  - DataCamp “Bringing it all together” assignment\n",
    "  - Coding assignment pt. 4\n",
    "\n",
    "Note: All work on DataCamp is logged. Don't try to fake it!\n",
    "\n",
    "Please email [me](mailto:jtao@fairfield.edu) if you have any problems or questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![DSB logo](img/Dolan.jpg)\n",
    "# Groupby and Pivoting\n",
    "\n",
    "## PD4E Chapter 10: Groupby Operations: Split-Apply-Combine\n",
    "### How do you read/manipulate/store data in Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
